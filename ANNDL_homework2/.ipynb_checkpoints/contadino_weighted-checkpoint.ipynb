{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1607728548889
    }
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from glob import iglob\n",
    "\n",
    "# costants\n",
    "SEED = 0xDED\n",
    "\n",
    "target_w = 512\n",
    "target_h = 512\n",
    "\n",
    "\n",
    "num_classes = 3    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1607728549371
    }
   },
   "outputs": [],
   "source": [
    "# usefull functions\n",
    "# Print iterations progress\n",
    "def printProgressBar (iteration, total, prefix = 'Progress', suffix = '', decimals = 1, length = 100, fill = 'â–ˆ', printEnd = \"\\r\"):\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()\n",
    "\n",
    "def fromCwd(path):\n",
    "    return os.path.join(os.getcwd(), path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1607728549641
    }
   },
   "outputs": [],
   "source": [
    "# intialization and common utilities\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "data_dir = fromCwd(\"data\")\n",
    "temp_dir = fromCwd(\"temp\")\n",
    "checkpoint_dir = fromCwd(\"checkpoints\")\n",
    "test_dir = fromCwd(\"test\")\n",
    "output_dir = fromCwd(\"output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1607728549851
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "   print(\"RIP no gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1607728771415
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 0\n",
      "Validation images: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#convert a mask in rgb to actual classes\n",
    "def rgb_to_class(mask_arr):\n",
    "    new_mask_arr = np.zeros(mask_arr.shape[:2], dtype=mask_arr.dtype)\n",
    "\n",
    "    # Use RGB dictionary in 'RGBtoTarget.txt' to convert RGB to target\n",
    "    new_mask_arr[np.where(np.all(mask_arr == [216, 124, 18], axis=-1))] = 0\n",
    "    new_mask_arr[np.where(np.all(mask_arr == [255, 255, 255], axis=-1))] = 1\n",
    "    new_mask_arr[np.where(np.all(mask_arr == [216, 67, 82], axis=-1))] = 2\n",
    "\n",
    "    return new_mask_arr  \n",
    "    \n",
    "    \n",
    "def process_image(pil_img):\n",
    "    img = pil_img.resize([target_w, target_h])\n",
    "    img = np.array(img) / 255.\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def process_mask(pil_img):\n",
    "    mask = pil_img.resize([target_w, target_h], resample=Image.NEAREST)\n",
    "    mask = np.array(mask)\n",
    "    mask = rgb_to_class(mask)\n",
    "    mask = np.expand_dims(mask, -1)\n",
    "\n",
    "    return mask\n",
    "\n",
    "# move all data to images or mask folders into dest dir\n",
    "def loadAllData(source_dir, valid_percent):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_valid = []\n",
    "    y_valid = []\n",
    "\n",
    "    for folder in iglob(source_dir+'/*/*'):\n",
    "\n",
    "        # here we got Images in subfolder\n",
    "        im_dir = os.path.join(folder, \"Images\")\n",
    "        ms_dir = os.path.join(folder, \"Masks\")\n",
    "        # read all images and masks\n",
    "        images = np.sort(os.listdir(im_dir))\n",
    "        masks = np.sort(os.listdir(ms_dir))\n",
    "\n",
    "        # make validation\n",
    "        val_sz = int(len(images) * valid_percent) + 1\n",
    "        for i in range(val_sz):\n",
    "            idx = np.random.randint(0, len(images))\n",
    "\n",
    "            if os.path.splitext(images[idx])[0] != os.path.splitext(masks[idx])[0]:\n",
    "                print(\"Image-Mask mismatch for: \" +images[idx]+\" -> \"+ masks[idx])\n",
    "\n",
    "            x_valid.append(process_image(Image.open(os.path.join(im_dir, images[idx]))))\n",
    "            y_valid.append(process_mask(Image.open(os.path.join(ms_dir, masks[idx]))))\n",
    "\n",
    "            sp = folder.split(\"/\")\n",
    "            printProgressBar(i+1, val_sz, prefix=str(i+1)+\"/\"+str(val_sz), suffix=\"Valid: \"+sp[-2]+\" - \"+ sp[-1])\n",
    "\n",
    "            # update refreshed folders without moved elements\n",
    "            images = np.delete(images, idx)\n",
    "            masks = np.delete(masks, idx)\n",
    "        \n",
    "        # train data\n",
    "        for idx in range(len(images)):\n",
    "            if os.path.splitext(images[idx])[0] != os.path.splitext(masks[idx])[0]:\n",
    "                print(\"Image-Mask mismatch for: \" +self.images[index]+\" -> \"+ self.masks[index])\n",
    "\n",
    "            x_train.append(process_image(Image.open(os.path.join(im_dir, images[idx]))))\n",
    "            y_train.append(process_mask(Image.open(os.path.join(ms_dir, masks[idx]))))\n",
    "\n",
    "            sp = folder.split(\"/\")\n",
    "            printProgressBar(idx+1, len(images), prefix=str(idx+1)+\"/\"+str(len(images)), suffix=\"Train: \" + sp[-2]+\" - \"+ sp[-1])\n",
    "\n",
    "    return np.array(x_train), np.array(y_train), np.array(x_valid), np.array(y_valid)\n",
    "\n",
    "#end    \n",
    "\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = loadAllData(data_dir, 0.1)\n",
    "\n",
    "\n",
    "print(\"Train images: \"+ str(len(x_train)))\n",
    "print(\"Validation images: \"+ str(len(x_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1607728773349
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a3edd27df26c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m   \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_size_inches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m   \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m   \u001b[0maugmented_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m   \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int32\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "for k in range(2):\n",
    "  # plot\n",
    "  fig, ax = plt.subplots(1, 2)\n",
    "  fig.set_size_inches(18, 5, forward=True)\n",
    "  \n",
    "  idx = np.random.randint(0, len(x_train))\n",
    "  augmented_img = x_train[idx]\n",
    "  target = y_train[idx]\n",
    "\n",
    "  augmented_img = augmented_img * 255  # denormalize\n",
    "\n",
    "  target_img = np.zeros([target.shape[0], target.shape[1], 3])\n",
    "  target = tf.squeeze(target, axis=-1)\n",
    "  #target = np.array(target).flatten()\n",
    "\n",
    "  print(np.unique(target))\n",
    "\n",
    "\n",
    "  target_img[np.where(target == 0)] = [0, 0, 0]\n",
    "  target_img[np.where(target == 1)] = [0, 255, 0] \n",
    "  target_img[np.where(target == 2)] = [255, 0, 0] \n",
    "\n",
    "  ax[0].imshow(np.uint8(augmented_img))\n",
    "  ax[1].imshow(np.uint8(target_img))\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1607728773623
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "vgg = keras.applications.VGG16(input_shape=[target_h, target_w, 3], include_top=False)\n",
    "for l in vgg.layers[:int(len(vgg.layers) * 0.7)]:\n",
    "    l.trainable = False\n",
    "\n",
    "vgg.summary()\n",
    "\n",
    "def up_block(down_in, prev, z_sz):\n",
    "    prev = keras.layers.UpSampling2D()(prev)\n",
    "    prev = keras.layers.Concatenate(axis=-1)([down_in, prev])\n",
    "    prev = keras.layers.Conv2D(z_sz,3, activation = 'relu', padding = 'same')(prev)\n",
    "    return keras.layers.Conv2D(z_sz,3, activation = 'relu', padding = 'same')(prev)\n",
    "\n",
    "mult = 1\n",
    "\n",
    "last = up_block(vgg.layers[-6].output, vgg.layers[-2].output, 256 * mult)\n",
    "last = up_block(vgg.layers[-10].output, last, 128 * mult)\n",
    "last = up_block(vgg.layers[-14].output, last, 64 * mult)\n",
    "last = up_block(vgg.layers[-17].output, last, 32 * mult)\n",
    "\n",
    "last = keras.layers.Conv2D(16 * mult, 3, activation = 'relu', padding = 'same')(last)\n",
    "last = keras.layers.Conv2D(16 * mult, 3, activation = 'relu', padding = 'same')(last)\n",
    "\n",
    "last = keras.layers.Conv2D(num_classes, 1, activation = 'softmax')(last)\n",
    "\n",
    "model = keras.Model(vgg.input, last)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1607728773857
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "learning_rate = 1e-5\n",
    "\n",
    "def weightedLoss(originalLossFunc, weightsList):\n",
    "\n",
    "    def lossFunc(true, pred):\n",
    "\n",
    "        axis = -1 #if channels last \n",
    "        #axis=  1 #if channels first\n",
    "\n",
    "\n",
    "        #argmax returns the index of the element with the greatest value\n",
    "        #done in the class axis, it returns the class index    \n",
    "        classSelectors = K.argmax(true, axis=axis) \n",
    "            #if your loss is sparse, use only true as classSelectors\n",
    "\n",
    "        #considering weights are ordered by class, for each class\n",
    "        #true(1) if the class index is equal to the weight index   \n",
    "        classSelectors = [K.equal(np.int64(i), classSelectors) for i in range(len(weightsList))]\n",
    "\n",
    "        #casting boolean to float for calculations  \n",
    "        #each tensor in the list contains 1 where ground true class is equal to its index \n",
    "        #if you sum all these, you will get a tensor full of ones. \n",
    "        classSelectors = [K.cast(x, K.floatx()) for x in classSelectors]\n",
    "\n",
    "        #for each of the selections above, multiply their respective weight\n",
    "        weights = [sel * w for sel,w in zip(classSelectors, weightsList)] \n",
    "\n",
    "        #sums all the selections\n",
    "        #result is a tensor with the respective weight for each element in predictions\n",
    "        weightMultiplier = weights[0]\n",
    "        for i in range(1, len(weights)):\n",
    "            weightMultiplier = weightMultiplier + weights[i]\n",
    "\n",
    "\n",
    "        #make sure your originalLossFunc only collapses the class axis\n",
    "        #you need the other axes intact to multiply the weights tensor\n",
    "        loss = originalLossFunc(true,pred) \n",
    "        loss = loss * weightMultiplier\n",
    "\n",
    "        return loss\n",
    "    return lossFunc\n",
    "\n",
    "\n",
    "def meanIoU(y_true, y_pred):\n",
    "    # get predicted class from softmax\n",
    "    y_pred = tf.expand_dims(tf.argmax(y_pred, -1), -1)\n",
    "\n",
    "    per_class_iou = []\n",
    "\n",
    "    for i in range(1,3): # exclude the background class 0\n",
    "      # Get prediction and target related to only a single class (i)\n",
    "      class_pred = tf.cast(tf.where(y_pred == i, 1, 0), tf.float32)\n",
    "      class_true = tf.cast(tf.where(y_true == i, 1, 0), tf.float32)\n",
    "      intersection = tf.reduce_sum(class_true * class_pred)\n",
    "      union = tf.reduce_sum(class_true) + tf.reduce_sum(class_pred) - intersection\n",
    "    \n",
    "      iou = (intersection + 1e-7) / (union + 1e-7)\n",
    "      per_class_iou.append(iou)\n",
    "\n",
    "    return tf.reduce_mean(per_class_iou)\n",
    "\n",
    "\n",
    "# compole model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss=weightedLoss(keras.losses.SparseCategoricalCrossentropy(),[1,1,5]), \n",
    "    metrics=[meanIoU] \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1607728774129
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "#checkpoint_dir = checkpoint_dir+str(now)\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# setup callbacks\n",
    "# -----------------------\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(checkpoint_dir, 'cp_{epoch:02d}.ckpt'), save_best_only=True, monitor='val_loss'),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "epochs = 2\n",
    "\n",
    "history = model.fit(\n",
    "          x=x_train,\n",
    "          y=y_train,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(x_valid, y_valid),\n",
    "          callbacks=callbacks\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot alla metrics \n",
    "idx = 1\n",
    "mtr = ['loss','meanIoU']\n",
    "\n",
    "plt.figure(figsize=(25, 8))\n",
    "\n",
    "for m in mtr:\n",
    "    x = history.history[m]\n",
    "    val_x = history.history['val_' + m]\n",
    "\n",
    "    plt.subplot(1, len(mtr), idx)\n",
    "    plt.plot(x, label='Training ' + m)\n",
    "    plt.plot(val_x, label='Validation ' + m)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation ' + m)\n",
    "    idx += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(img):\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "# return {rle crop prediction, rle weed prediction} img shape\n",
    "def make_prediction(model, image):\n",
    "\n",
    "    #print(\"Original size: \"+ str(image.size))\n",
    "\n",
    "    img = image.resize([target_w, target_h]) # resize to the network expected size and keep a copy of the original img\n",
    "    img = np.array(img) / 255. # rescale\n",
    "    img = tf.expand_dims(img, 0) # add \"batch\" dimension\n",
    "\n",
    "    out = model(img, training=False) # predict\n",
    "\n",
    "    out= tf.squeeze(out, 0) # remove batch dimension to get a 3d vector\n",
    "    # we got a 3d vector with 3 deph and we need to rescale it to original input size\n",
    "    # so we denormalize if (output of softmax is 0 < val < 1)\n",
    "    # and we treat it as img to resize in plt\n",
    "    out = Image.fromarray(np.uint8(out * 255.)).resize(image.size)\n",
    "    #print(\"Predictions:\" + str(out.size))\n",
    "    out = np.array(out)\n",
    "    # rescale and resize should preserve the old max channels\n",
    "    # so we can ignore the rescaling to 0-1 again\n",
    "    out = tf.math.argmax(out, axis=-1) \n",
    "\n",
    "    \n",
    "\n",
    "    return out, image.size\n",
    "\n",
    "# create function to evaluate the model and output results in requeisted format\n",
    "def output_predictions(model, test_dir):\n",
    "    submission_dict = {}\n",
    "    #print(test_dir)\n",
    "\n",
    "    # iterate all datasets keeping name\n",
    "    for team in os.listdir(test_dir): #team == dataset name\n",
    "        team_dir = os.path.join(test_dir, team)\n",
    "\n",
    "        # iterate all corps for a dataset keeping name\n",
    "        for crop in os.listdir(team_dir):\n",
    "            crop_dict = {}\n",
    "            img_dir = os.path.join(team_dir, crop)\n",
    "            img_dir = os.path.join(img_dir, \"Images\")\n",
    "            # iterate all images \n",
    "            files = os.listdir(img_dir)\n",
    "            i = 0\n",
    "            for fl in files:\n",
    "                #print(\"img: \"+ fl)\n",
    "                # get prediction from model\n",
    "                image = Image.open(os.path.join(img_dir, fl))\n",
    "                prediction, shape = make_prediction(model, image)\n",
    "                \n",
    "                prediction = np.array(prediction)\n",
    "\n",
    "                filename, file_extension = os.path.splitext(fl)\n",
    "                # prepare output dict\n",
    "                submission_dict[filename] = {\n",
    "                    'shape': shape,\n",
    "                    'team': team,\n",
    "                    'crop': crop,\n",
    "                    'segmentation': {'crop': rle_encode(prediction == 1), 'weed':rle_encode(prediction == 2)}\n",
    "                }\n",
    "\n",
    "                i += 1\n",
    "                printProgressBar(i, len(files), prefix=\"Prediction\", suffix=team+\" - \"+crop)\n",
    "            # end for fl\n",
    "        # end for crop\n",
    "    #end for team\n",
    "\n",
    "    return submission_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot result of a validation image to understand if net is learning right\n",
    "samples = 3\n",
    "\n",
    "for i in range(samples):\n",
    "    idx = np.random.randint(0, len(x_valid))\n",
    "    img = x_valid[idx]\n",
    "    mask = y_valid[idx]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3)\n",
    "    fig.set_size_inches(18, 5, forward=True)\n",
    "\n",
    "    img = np.array(img) * 255\n",
    "    i = Image.fromarray(np.uint8(img))\n",
    "    out, shape = make_prediction(model, i)\n",
    "\n",
    "    # expected mask\n",
    "\n",
    "    target_img = np.zeros([target.shape[0], target.shape[1], 3])\n",
    "    target = tf.squeeze(mask, axis=-1)\n",
    "\n",
    "    target_img[np.where(target == 0)] = [0, 0, 0]\n",
    "    target_img[np.where(target == 1)] = [0, 255, 0] \n",
    "    target_img[np.where(target == 2)] = [255, 0, 0] \n",
    "\n",
    "    #prediction\n",
    "    out_img = np.zeros([out.shape[0], out.shape[1], 3])\n",
    "\n",
    "    out_img[np.where(out == 0)] = [0, 0, 0]\n",
    "    out_img[np.where(out == 1)] = [0, 255, 0] \n",
    "    out_img[np.where(out == 2)] = [255, 0, 0] \n",
    "\n",
    "    ax[0].imshow(np.uint8(img))\n",
    "    ax[1].imshow(np.uint8(target_img))\n",
    "    ax[2].imshow(np.uint8(out_img))\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# output last model\n",
    "print(\"Making prediction with latest model...\")\n",
    "loss, metrics = model.evaluate(x=x_valid, y=y_valid, verbose=2, steps=len(x_valid))\n",
    "\n",
    "iou = \"{:5.2f}\".format(100 * metrics)\n",
    "loss = \"{:5.2f}\".format(loss)\n",
    "\n",
    "print(\"Last model expected results: loss:{}, iou: {}%\".format(loss, iou))\n",
    "res = output_predictions(model, test_dir)\n",
    "\n",
    "name = '0latest_iou' + iou + '_loss' + loss +'.json'\n",
    "with open(os.path.join(output_dir, name), 'w') as fp:\n",
    "        json.dump(res, fp)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls /kaggle/temp/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# predict with checkpoint models\n",
    "print(\"Making prediction with best models, this may take a while...\")\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "num = 0\n",
    "ckps = os.listdir(checkpoint_dir)\n",
    "ckps = ['cp_32.ckpt']\n",
    "\n",
    "for cp in ckps:\n",
    "    path_to_model = os.path.join(checkpoint_dir, cp)\n",
    "    m2 = tf.keras.models.load_model(path_to_model, custom_objects={'meanIoU':meanIoU})\n",
    "    \n",
    "\n",
    "    loss, metrics = m2.evaluate(x=x_valid, y=y_valid, verbose=2, steps=len(x_valid))\n",
    "\n",
    "    #acc = \"{:5.2f}\".format(100 * metrics)\n",
    "    iou = \"{:5.2f}\".format(100 * metrics)\n",
    "    loss = \"{:5.2f}\".format(loss)\n",
    "\n",
    "    print(\"Model expected results: loss:{}, iou: {}%\".format(loss, iou))\n",
    "    res = output_predictions(model, test_dir)\n",
    "\n",
    "    # write to file\n",
    "   \n",
    "    name = 'iou' + iou + '_loss' + loss +'.json'\n",
    "    with open(os.path.join(output_dir, name), 'w') as fp:\n",
    "        json.dump(res, fp)\n",
    "\n",
    "    num += 1\n",
    "    print(\"Progress: \"+str(num)+\"/\"+str(len(ckps)))\n",
    "\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
