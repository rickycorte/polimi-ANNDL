{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\Desktop\\ANNDL_projects\\ANNDL_homework2\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "# costants\n",
    "SEED = 0xDED\n",
    "\n",
    "target_w = 2048\n",
    "target_h = 1536\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "use_crop = False\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialization and common utilities\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def fromCwd(path):\n",
    "    return os.path.join(os.getcwd(), path)\n",
    "\n",
    "# train_dir = fromCwd(\"training\")\n",
    "# valid_dir = fromCwd(\"validation\")\n",
    "# data_dir = fromCwd(\"data\")\n",
    "# temp_dir = fromCwd(\"temp\")\n",
    "\n",
    "#local directory C:\\Users\\simon\\Desktop\\Dataset\\Development_Dataset\n",
    "\n",
    "train_dir = os.path.join(\"C:/Users/simon/Desktop/Dataset\",\"training\")\n",
    "valid_dir = os.path.join(\"C:/Users/simon/Desktop/Dataset\",\"validation\")\n",
    "data_dir = os.path.join(\"C:/Users/simon/Desktop/Dataset/Development_Dataset\",\"Training\")\n",
    "temp_dir = os.path.join(\"C:/Users/simon/Desktop/Dataset\",\"temp\")\n",
    "\n",
    "if not os.path.exists(train_dir):\n",
    "    os.mkdir(train_dir)\n",
    "    os.mkdir(valid_dir)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Skipped] Directory already exists: C:/Users/simon/Desktop/Dataset\\training\\Images\n"
     ]
    }
   ],
   "source": [
    "# crop image\n",
    "\n",
    "# make crops and return the sub images\n",
    "def cropImg(image, target_w, target_h):\n",
    "    w, h = image.size\n",
    "    div_x = int(w/target_w)\n",
    "    div_y = int(w/target_h)\n",
    "    if div_x <= 0:\n",
    "        div_x = 1\n",
    "    if div_y <= 0:   \n",
    "        div_y = 1\n",
    "    \n",
    "\n",
    "    w /= div_x\n",
    "    h /= div_y\n",
    "\n",
    "    sub_images = []\n",
    "    # x and y are swapped to have array \"rows\" match image rows\n",
    "    for y in range(div_y):\n",
    "        for x in range(div_y):\n",
    "            sz = (x*w, y*h, x*w + w, y*h + h)\n",
    "            sub_images.append(image.crop(sz))\n",
    "\n",
    "    return sub_images\n",
    "\n",
    "#save images to disk\n",
    "def saveImagesArray(images, original_name, dest_dir):\n",
    "    filename, file_extension = os.path.splitext(original_name)\n",
    "    for i in range(len(images)):\n",
    "        img = images[i]\n",
    "        w, h = img.size\n",
    "        img.save(os.path.join(dest_dir, filename + \"_cp\" + str(i) + \"_\" + str(w) + \"x\" + str(h) + \".\" + file_extension))\n",
    "\n",
    "# recursively crop all images into a directory maitaining the same\n",
    "# internal structure to the destination\n",
    "def cropAllTo(source_dir, dest_dir, target_w, target_h):\n",
    "    if(os.path.exists(dest_dir)):\n",
    "        print(\"[Skipped] Directory already exists: \"+ dest_dir)\n",
    "        return\n",
    "    else:\n",
    "        os.mkdir(dest_dir)\n",
    "\n",
    "    # iterate all files and check if directory or not\n",
    "    for fl in os.listdir(source_dir): # return relative paths\n",
    "        if os.path.isdir(os.path.join(source_dir, fl)):\n",
    "            # start again with the new source as the dir path\n",
    "            cropAllTo(os.path.join(source_dir, fl), os.path.join(dest_dir, fl), target_w, target_h) \n",
    "        else:\n",
    "            im = Image.open(os.path.join(source_dir, fl))\n",
    "            # here we got an image and se shold split it and save\n",
    "            images = cropImg(im, target_w, target_h)\n",
    "            saveImagesArray(images, fl, dest_dir)\n",
    "    print(\"Generated \" + dest_dir)\n",
    "\n",
    "\n",
    "# move all data to images or mask folders into dest dir\n",
    "def moveRecursive(source_dir, folders, percent):\n",
    "    print(folders)\n",
    "    \n",
    "    items = os.listdir(source_dir)\n",
    "    print(\"Moving from \"+ source_dir)\n",
    "\n",
    "    if not \"Images\" in items: # normal top folder we should explore all its sub folders\n",
    "        for fold in items:\n",
    "            moveRecursive(os.path.join(source_dir, fold), folders, percent)\n",
    "        return # no more to do in this folder\n",
    "\n",
    "    # here we got Images in subfolder\n",
    "    im_dir = os.path.join(source_dir, \"Images\")\n",
    "    ms_dir = os.path.join(source_dir, \"Masks\")\n",
    "    # read all images and masks\n",
    "    images = os.listdir(im_dir)\n",
    "    masks = os.listdir(ms_dir)\n",
    "\n",
    "    # make validation\n",
    "    for i in range(int(len(images) * percent)):\n",
    "        idx = np.random.randint(0, len(images))\n",
    "\n",
    "        # move both image and mask to validation folder\n",
    "        os.rename(os.path.join(im_dir, images[idx]), os.path.join(folders[2], images[idx]))\n",
    "        os.rename(os.path.join(ms_dir, masks[idx]), os.path.join(folders[3], masks[idx]))\n",
    "\n",
    "        # update refreshed folders without moved elements\n",
    "        images = os.listdir(im_dir)\n",
    "        masks = os.listdir(ms_dir)\n",
    "\n",
    "    # create train set\n",
    "    for img in images:\n",
    "        os.rename(os.path.join(im_dir, img), os.path.join(folders[0], img))\n",
    "    for msk in masks:\n",
    "        os.rename(os.path.join(ms_dir, msk), os.path.join(folders[1], msk))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# move all data from subfolders in source folder to Images/Mask folders in dest folder\n",
    "def prepareTrainData(source_dir, train_dir, valid_dir, percent = 0.1):\n",
    "\n",
    "    folders = [] # order: Test_img | Test_mask | valid_img | valid_mask\n",
    "    for parent in [train_dir, valid_dir]:\n",
    "        for sub in [\"Images\", \"Masks\"]:\n",
    "            folders.append(os.path.join(parent,sub))\n",
    "\n",
    "    # check if a folder already exist and skip \n",
    "    for f in folders:\n",
    "        if os.path.exists(f):\n",
    "            print(\"[Skipped] Directory already exists: \"+ f)\n",
    "            return folders\n",
    "\n",
    "    # create folders\n",
    "    for f in folders:   \n",
    "        os.makedirs(f)\n",
    "\n",
    "    moveRecursive(source_dir, folders, percent)\n",
    "    print(\"Train and Valid set ready\")\n",
    "\n",
    "    return folders\n",
    "\n",
    "\n",
    "if not os.path.exists(temp_dir):\n",
    "    shutil.copytree(data_dir, temp_dir) # required to copy everythin because preparaTrainData move images\n",
    "\n",
    "folders = prepareTrainData(temp_dir, train_dir, valid_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# def printGrid(sub_im):\n",
    "#     plt.figure(figsize=(27, 27))\n",
    "#     for i in range(len(sub_im)):\n",
    "#         ax = plt.subplot(IMG_DIVIDER, IMG_DIVIDER ,i+1)\n",
    "        \n",
    "#         plt.imshow(np.uint8(sub_im[i]))\n",
    "#         plt.axis(\"off\")\n",
    "        \n",
    "#     plt.plot()\n",
    "\n",
    "\n",
    "# #printGrid(sub_images)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create generators\n",
    "rot_range = 20\n",
    "h_shift = 10\n",
    "w_shift = 10\n",
    "h_flip = True\n",
    "w_flip = True\n",
    "zoom = 0.15\n",
    "\n",
    "img_data_gen = ImageDataGenerator(\n",
    "#     rotation_range=rot_range,\n",
    "#     width_shift_range=w_shift,\n",
    "#     height_shift_range=h_shift,\n",
    "#     zoom_range=zoom,\n",
    "#     horizontal_flip=h_flip,\n",
    "#     vertical_flip=w_flip,\n",
    "#     fill_mode='reflect'\n",
    "    rescale=1./255\n",
    "    )\n",
    "\n",
    "mask_data_gen = ImageDataGenerator(\n",
    "#     rotation_range=rot_range,\n",
    "#     width_shift_range=w_shift,\n",
    "#     height_shift_range=h_shift,\n",
    "#     zoom_range=zoom,\n",
    "#     horizontal_flip=h_flip,\n",
    "#     vertical_flip=w_flip,\n",
    "#     fill_mode='reflect'\n",
    "    rescale=1./255\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #convert a mask in rgb to actual classes\n",
    "  def rgb_to_class(mask_arr):\n",
    "\n",
    "    new_mask_arr = np.zeros(mask_arr.shape[:2], dtype=mask_arr.dtype)\n",
    "\n",
    "    # Use RGB dictionary in 'RGBtoTarget.txt' to convert RGB to target\n",
    "    new_mask_arr[np.where(np.all(mask_arr == [0, 0, 0], axis=-1))] = 0\n",
    "    new_mask_arr[np.where(np.all(mask_arr == [216, 124, 18], axis=-1))] = 0\n",
    "    new_mask_arr[np.where(np.all(mask_arr == [255, 255, 255], axis=-1))] = 1\n",
    "    new_mask_arr[np.where(np.all(mask_arr == [216, 67, 82], axis=-1))] = 2\n",
    "\n",
    "    return new_mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create custom generator\n",
    "\n",
    "class CustomGenerator(tf.keras.utils.Sequence):\n",
    "\n",
    "  def __init__(self, directory, img_generator=None, mask_generator=None, preprocessing_function=None, out_shape=[256, 256]):\n",
    "    self.img_generator = img_generator\n",
    "    self.mask_generator = mask_generator\n",
    "    self.preprocessing_function = preprocessing_function\n",
    "    self.out_shape = out_shape\n",
    "    self.im_path = os.path.join(directory, \"Images\")\n",
    "    self.ms_path = os.path.join(directory, \"Masks\")\n",
    "    self.images = np.sort(os.listdir(self.im_path)) \n",
    "    self.masks = np.sort(os.listdir(self.ms_path)) \n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.images)\n",
    "\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # Read Image\n",
    "    img = Image.open(os.path.join(self.im_path, self.images[index]))\n",
    "    mask = Image.open(os.path.join(self.ms_path, self.masks[index]))\n",
    "\n",
    "    # Resize image and mask\n",
    "    img = img.resize(self.out_shape)\n",
    "    mask = mask.resize(self.out_shape, resample=Image.NEAREST)\n",
    "    \n",
    "    img_arr = np.array(img)\n",
    "    mask_arr = np.array(mask)\n",
    "\n",
    "    out_mask = []\n",
    "\n",
    "    if self.img_generator is not None and self.mask_generator is not None:\n",
    "        # Perform data augmentation\n",
    "        img_t = self.img_generator.get_random_transform(img_arr.shape, seed=SEED)\n",
    "        mask_t = self.mask_generator.get_random_transform(mask_arr.shape, seed=SEED)\n",
    "        img_arr = self.img_generator.apply_transform(img_arr, img_t)\n",
    "        # ImageDataGenerator use bilinear interpolation for augmenting the images.\n",
    "        # Thus, when applied to the masks it will output 'interpolated classes', which\n",
    "        # is an unwanted behaviour. As a trick, we can transform each class mask \n",
    "        # separately and then we can cast to integer values (as in the binary segmentation notebook).\n",
    "        # Finally, we merge the augmented binary masks to obtain the final segmentation mask.\n",
    "        out_mask = np.zeros_like(mask_arr)\n",
    "        for c in np.unique(mask_arr):\n",
    "          if c > 0:\n",
    "            curr_class_arr = np.float32(mask_arr == c)\n",
    "            curr_class_arr = self.mask_generator.apply_transform(curr_class_arr, mask_t)\n",
    "            # from [0, 1] to {0, 1}\n",
    "            curr_class_arr = np.uint8(curr_class_arr)\n",
    "            # recover original class\n",
    "            curr_class_arr = curr_class_arr * c \n",
    "            out_mask += curr_class_arr\n",
    "    else:\n",
    "      out_mask = mask_arr\n",
    "    \n",
    "    if self.preprocessing_function is not None:\n",
    "        img_arr = self.preprocessing_function(img_arr)\n",
    "\n",
    "    out_mask = rgb_to_class(np.float32(out_mask))\n",
    "    out_mask = np.expand_dims(out_mask, -1)\n",
    "\n",
    "\n",
    "    return img_arr, out_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 648\n",
      "Validation dataset size: 72\n"
     ]
    }
   ],
   "source": [
    "train = CustomGenerator(train_dir,\n",
    "                        img_generator=img_data_gen, \n",
    "                        mask_generator=mask_data_gen,\n",
    "                        out_shape=[target_w, target_h]\n",
    "                        )\n",
    "\n",
    "valid = CustomGenerator(valid_dir, out_shape=[target_w, target_h])\n",
    "\n",
    "print(\"Train dataset size: \"+ str(len(train)))\n",
    "print(\"Validation dataset size: \" + str(len(valid)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RepeatDataset shapes: ((None, 1536, 2048, 3), (None, 1536, 2048, 1)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "out_pt = (tf.float32, tf.float32)\n",
    "out_shp = ([target_h, target_w, 3], [target_h, target_w, 1])\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: train, output_types=out_pt, output_shapes=out_shp).batch(batch_size).repeat()\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: valid, output_types=out_pt, output_shapes=out_shp).batch(batch_size).repeat()\n",
    "\n",
    "print(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# from matplotlib import cm\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# # Assign a color to each class\n",
    "# evenly_spaced_interval = np.linspace(0, 1, 20)\n",
    "# colors = [cm.rainbow(x) for x in evenly_spaced_interval]\n",
    "\n",
    "# iterator = iter(train_dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in range(2):\n",
    "#   # plot\n",
    "#   fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "#   augmented_img, target = next(iterator)\n",
    "#   augmented_img = augmented_img[0]   # First element\n",
    "#   augmented_img = augmented_img  # denormalize\n",
    "\n",
    "\n",
    "#   target = np.array(target[0, ..., 0])   # First element (squeezing channel dimension)\n",
    "\n",
    "#   print(np.unique(target))\n",
    "\n",
    "#   target_img = np.zeros([target.shape[0], target.shape[1], 3])\n",
    "\n",
    "#   target_img[np.where(target == 0)] = [0, 0, 0]\n",
    "#   target_img[np.where(target == 1)] = [0, 255, 0] \n",
    "#   target_img[np.where(target == 2)] = [255, 0, 0] \n",
    "\n",
    "#   ax[0].imshow(np.uint8(augmented_img))\n",
    "#   ax[1].imshow(np.uint8(target_img))\n",
    "\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as keras\n",
    "  \n",
    "num_classes = 3    \n",
    "# input layer  \n",
    "\n",
    "\n",
    "img_w = 2048\n",
    "img_h = 1536\n",
    "\n",
    "inputs = Input(shape = [img_h,img_w,3])\n",
    "\n",
    "\n",
    "conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "drop4 = Dropout(0.1)(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "drop5 = Dropout(0.1)(conv5)\n",
    "\n",
    "up6 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "merge6 = concatenate([drop4,up6], axis = 3)\n",
    "conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "up7 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "merge7 = concatenate([conv3,up7], axis = 3)\n",
    "conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "up8 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "merge8 = concatenate([conv2,up8], axis = 3)\n",
    "conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "up9 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "merge9 = concatenate([conv1,up9], axis = 3)\n",
    "conv9 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "conv9 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "conv9 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "conv10 = Conv2D(num_classes, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "model = Model(inputs = inputs, outputs = conv10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization params\n",
    "# -------------------\n",
    "import tensorflow.keras as K\n",
    "# Loss\n",
    "# Sparse Categorical Crossentropy to use integers (mask) instead of one-hot encoded labels\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy() \n",
    "# learning rate\n",
    "lr = 3e-5\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "# -------------------\n",
    "\n",
    "# Here we define the intersection over union for each class in the batch.\n",
    "# Then we compute the final iou as the mean over classes\n",
    "#meanIoU = tf.keras.metrics.MeanIoU(num_classes = 3)\n",
    "\n",
    "def meanIoU(y_true, y_pred):\n",
    "    # get predicted class from softmax\n",
    "    y_pred = tf.expand_dims(tf.argmax(y_pred, -1), -1)\n",
    "\n",
    "    per_class_iou = []\n",
    "\n",
    "    for i in range(0,3): # exclude the background class 0\n",
    "      # Get prediction and target related to only a single class (i)\n",
    "      class_pred = tf.cast(tf.where(y_pred == i, 1, 0), tf.float32)\n",
    "      class_true = tf.cast(tf.where(y_true == i, 1, 0), tf.float32)\n",
    "      intersection = tf.reduce_sum(class_true * class_pred)\n",
    "      union = tf.reduce_sum(class_true) + tf.reduce_sum(class_pred) - intersection\n",
    "    \n",
    "      iou = (intersection + 1e-7) / (union + 1e-7)\n",
    "      per_class_iou.append(iou)\n",
    "\n",
    "    return tf.reduce_mean(per_class_iou)\n",
    "\n",
    "\n",
    "# Validation metrics\n",
    "# ------------------\n",
    "metrics = ['accuracy', meanIoU]\n",
    "# ------------------\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 648.0 steps, validate for 72.0 steps\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_dataset,\n",
    "          epochs=1,  #### set repeat in training dataset\n",
    "          steps_per_epoch=len(train)/batch_size,\n",
    "          validation_data=valid_dataset,\n",
    "          validation_steps=len(valid)/batch_size)\n",
    "\n",
    "val_acc = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "#test folder\n",
    "test_dir = \"C:\\\\Users\\\\simon\\\\Desktop\\\\Dataset\\\\Development_Dataset\\\\Test_Dev\"\n",
    "\n",
    "listOfFiles = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(test_dir):\n",
    "    listOfFiles += [os.path.join(dirpath, file) for file in filenames]\n",
    "        \n",
    "# list of files contains all the directories of the test images \n",
    "\n",
    "\n",
    "test_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "temp_test_folder = \"C:\\\\Users\\\\simon\\\\Desktop\\\\Dataset\\\\temp_test\"\n",
    "temp_class_folder = os.path.join(temp_test_folder,\"test\")\n",
    "\n",
    "submission_folder = \"C:\\\\Users\\\\simon\\\\Desktop\\\\Dataset\\\\submission\"\n",
    "\n",
    "\n",
    "if not os.path.exists(submission_folder):\n",
    "    os.mkdir(submission_folder)\n",
    "\n",
    "if not os.path.exists(temp_test_folder):\n",
    "    os.mkdir(temp_test_folder)\n",
    "    \n",
    "if not os.path.exists(temp_class_folder):\n",
    "    os.mkdir(temp_class_folder)\n",
    "\n",
    "    \n",
    "for path in listOfFiles:\n",
    "    image_name = (path.split('\\\\'))[-1] \n",
    "    shutil.copy(path, os.path.join(temp_class_folder,image_name))\n",
    "\n",
    "                                  \n",
    "\n",
    "\n",
    "test_gen = test_data_gen.flow_from_directory(\n",
    "    temp_test_folder,\n",
    "    target_size=(img_w, img_h), \n",
    "    color_mode='rgb',\n",
    "    classes = ['test'],\n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "test_gen.reset()\n",
    "\n",
    "images = test_gen.filenames\n",
    "\n",
    "predictions = model.predict_generator(test_gen, len(test_gen), verbose=1)\n",
    "\n",
    "\n",
    "# out = model(img, training=False) # predict     \n",
    "# out = tf.math.argmax(out, axis=-1) # compress output in 2d tensor with 0,1,2 values for each pixel\n",
    "# out= tf.squeeze(out, 0) # remove batch dimension an leav 2d\n",
    "\n",
    "predictions = tf.math.argmax(predictions,axis=0)\n",
    "\n",
    "print(predictions.shape)\n",
    "print(predictions)\n",
    "\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - foreground, 0 - background\n",
    "    Returns run length as string formatted\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "counter = 0\n",
    "submission_dict = {}\n",
    "\n",
    "for p in predictions:\n",
    "    img_name = (images[counter].split('\\\\'))[-1]\n",
    "    img_name = img_name[:-4]\n",
    "    splitted_name = img_name.split('_')\n",
    "    team = splitted_name[0].capitalize()\n",
    "    crop = splitted_name[1].capitalize()\n",
    "    # load mask <- HERE you should have your segmentation model instead\n",
    "    #mask_arr = np.load('./predictions/arr_mask_example.npy')\n",
    "    mask_arr = np.array(p)\n",
    "    \n",
    "    submission_dict[img_name] = {}\n",
    "    submission_dict[img_name]['shape'] = mask_arr.shape\n",
    "    submission_dict[img_name]['team'] = team\n",
    "    submission_dict[img_name]['crop'] = crop\n",
    "    submission_dict[img_name]['segmentation'] = {}\n",
    "\n",
    "    # RLE encoding\n",
    "    # crop\n",
    "    rle_encoded_crop = rle_encode(mask_arr == 1)\n",
    "    # weed\n",
    "    rle_encoded_weed = rle_encode(mask_arr == 2)\n",
    "\n",
    "    submission_dict[img_name]['segmentation']['crop'] = rle_encoded_crop\n",
    "    submission_dict[img_name]['segmentation']['weed'] = rle_encoded_weed\n",
    "\n",
    "    # Please notice that in this example we have a single prediction.\n",
    "    # For the competition you have to provide segmentation for each of\n",
    "    # the test images.\n",
    "    print(img_name)\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "# Finally, save the results into the submission.json file\n",
    "with open(os.path.join(submission_folder,'submission.json'), 'w') as f:\n",
    "    json.dump(submission_dict, f)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
