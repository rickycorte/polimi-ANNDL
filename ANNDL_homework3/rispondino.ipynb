{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np \nimport os\nfrom PIL import Image\nimport json\nimport matplotlib.pyplot as plt\n\nSEED = 1234\n\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)\n\ndef fromCwd(path):\n    return os.path.join(os.getcwd(), path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if os.path.exists(\"/kaggle\"):\n    # kaggle settings\n    dataset_dir = \"/kaggle/input/vqaset/VQA_Dataset\"\n    output_dir = \"/kaggle/working\"\nelif os.path.exists(\"/content/gdrive\"):\n    # colab settings here\n    dataset_dir = \"\"\n    output_dir = \"\"\nelse:\n    # local settings\n    dataset_dir = fromCwd(\"data\")\n    output_dir = fromCwd(\"output\")\n\n\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\ntrain_json_path = os.path.join(dataset_dir,'train_questions_annotations.json')\nimg_path = os.path.join(dataset_dir,'Images')\n\ntest_json_path = os.path.join(dataset_dir,'test_questions.json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_dict = {\n        '0': 0,\n        '1': 1,\n        '2': 2,\n        '3': 3,\n        '4': 4,\n        '5': 5,\n        'apple': 6,\n        'baseball': 7,\n        'bench': 8,\n        'bike': 9,\n        'bird': 10,\n        'black': 11,\n        'blanket': 12,\n        'blue': 13,\n        'bone': 14,\n        'book': 15,\n        'boy': 16,\n        'brown': 17,\n        'cat': 18,\n        'chair': 19,\n        'couch': 20,\n        'dog': 21,\n        'floor': 22,\n        'food': 23,\n        'football': 24,\n        'girl': 25,\n        'grass': 26,\n        'gray': 27,\n        'green': 28,\n        'left': 29,\n        'log': 30,\n        'man': 31,\n        'monkey bars': 32,\n        'no': 33,\n        'nothing': 34,\n        'orange': 35,\n        'pie': 36,\n        'plant': 37,\n        'playing': 38,\n        'red': 39,\n        'right': 40,\n        'rug': 41,\n        'sandbox': 42,\n        'sitting': 43,\n        'sleeping': 44,\n        'soccer': 45,\n        'squirrel': 46,\n        'standing': 47,\n        'stool': 48,\n        'sunny': 49,\n        'table': 50,\n        'tree': 51,\n        'watermelon': 52,\n        'white': 53,\n        'wine': 54,\n        'woman': 55,\n        'yellow': 56,\n        'yes': 57\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# utility functions\n\n# lower text in data items\ndef normalize_question(question):\n    return question.lower()\n\n# find max question lenght in the set\ndef calc_max_question_len(data):\n    mval = 0\n    for k in data:\n        v = len(data[k][\"question\"].split())\n        if mval < v:\n            mval = v\n    \n    return mval\n\n\n# convert answer to integer\ndef convert_answer(answer):\n    return tf.keras.utils.to_categorical(labels_dict[answer], num_classes=len(labels_dict), dtype='float32')\n\n# generate image path from image_id\ndef make_image_path(img_id):\n    return os.path.join(img_path, img_id + \".png\")\n\ndef load_image(path, size):\n    img = Image.open(path).convert('RGB')\n    img = img.resize(size)\n    return np.array(img) / 255.\n\n#################################################################################################################\n\n\n# tokenize and pad question\ndef tokenize_question(question, tokenizer, pad_to_size):\n    word_index = tokenizer.word_index\n  \n    result = tokenizer.texts_to_sequences([question])[0] # tokenize\n   \n    pad_num = pad_to_size - len(result)\n    # pad to max len with zeros (<pad>)\n    if pad_num > 0:\n        for i in range(0, pad_num):\n            result.append(0)\n\n    # append <eos> token\n    result.append(word_index['<eos>']) #TODO: is it really needed?\n\n    return result\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load train json\ntrain_data = []\n\nwith open(train_json_path) as json_file:\n    train_data = json.load(json_file)\n\n# normalize questions and answers\nfor k in train_data:\n    train_data[k][\"question\"] = normalize_question(train_data[k][\"question\"])\n    train_data[k][\"answer\"] = convert_answer(train_data[k][\"answer\"])\n    train_data[k][\"image_path\"] = make_image_path(train_data[k][\"image_id\"])\n\n# get max question lenght\nmax_question_len = calc_max_question_len(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n\n# fit tokenizer to data\ndef fit_tokenizer(tok, data):\n    qset = set()\n\n    for key in data:\n        qset.add(data[key]['question'])\n\n    tok.fit_on_texts(qset)\n    # create custom eos token as last token\n    tok.word_index['<eos>'] = len(tok.word_index) + 1 # +1 because 0 index is reserved and real last element has value of len(tok.word_index)\n    return tok\n\n\n# we create a global tokenizer to share in all application in this way we have\nmax_words = 10e4\ntokenizer = Tokenizer(num_words = max_words, oov_token='<unk>')\n\ntokenizer = fit_tokenizer(tokenizer, train_data)\n\n\n# tokenize questios\nfor k in train_data:\n    train_data[k][\"question_tok\"] = tokenize_question(train_data[k][\"question\"], tokenizer, max_question_len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print sample\nprint(train_data['1'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make validation data\nimport random\n\nvalid_percent = 0.2\n\nprint(\"Original size: {}\".format(len(train_data)))\n\n# create subsample of train data\nvalid_data = dict(random.sample(train_data.items(), int(len(train_data) * valid_percent)))\n\n# remove from train set\nfor k in valid_data:\n    del train_data[k]\n\nprint(\"train ({}) + valid ({}) = {}\".format(len(train_data), len(valid_data), len(train_data)+len(valid_data)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create custom data generator\n\n# create custom data generator\n\nclass DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, data, image_shape):\n        self.image_shape = image_shape\n        self.data = data\n        self.id_list = [key for key in self.data]\n        \n    def __len__(self):\n        return len(self.id_list)\n\n    def __getitem__(self, index):\n        block = self.data[self.id_list[index]]\n\n        return {'image': load_image(block[\"image_path\"], self.image_shape), 'question': block[\"question_tok\"]}, block['answer']\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_image_shape = [224, 224]\nbatch_size = 32\n\nprefetch_sz = tf.data.experimental.AUTOTUNE\n\nout_shape = ({'image': target_image_shape + [3], 'question': [max_question_len+1]}, [len(labels_dict)])\nout_type = ({'image': tf.float32, 'question': tf.int32}, tf.float32)\n\ntrain_gen = DataGenerator(train_data, image_shape= target_image_shape)\nvalid_gen = DataGenerator(valid_data, image_shape= target_image_shape)\n\ntrain_dataset = tf.data.Dataset.from_generator(lambda: train_gen, output_shapes= out_shape, output_types= out_type).batch(batch_size).repeat().prefetch(prefetch_sz)\nvalid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, output_shapes= out_shape, output_types= out_type).batch(batch_size).repeat().prefetch(prefetch_sz)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_dataset)\n\nprint(valid_dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = len(labels_dict)\nimg_shape = target_image_shape + [3]\n\nmax_question_len += 1 # add end of sequence token\n# ------------------------ CNN ----------------------\n\n\nvgg = tf.keras.applications.VGG16(include_top = False, input_shape = img_shape)\n\nfor l in vgg.layers[:int(len(vgg.layers)*0.75)]:\n  l.trainable = False \n\nvgg_output = tf.keras.layers.GlobalAveragePooling2D()(vgg.output)\nvgg_output = tf.keras.layers.Dense(units = 1024,activation = 'softmax')(vgg_output)\n#vgg.summary()\nvgg.layers[0]._name = 'image' # rename layer to make it compatible with named dataset values\n\ncnn = tf.keras.Model(inputs = vgg.input, outputs = vgg_output)\n\n\n# ------------------------ RNN ----------------------\n\nEMBEDDING_SIZE = 32\n\n# ENCODER\n# -------\n# in keras out = layer(input)\n\nencoder_input = tf.keras.Input(shape=[max_question_len], name='question')\n\nencoder_embedding_layer = tf.keras.layers.Embedding(len(tokenizer.word_index)+1, EMBEDDING_SIZE, input_length=max_question_len, mask_zero=True)\n\nencoder_embedding_out = encoder_embedding_layer(encoder_input)\n\n# I need 128 units because I have 4 words each embedded in 32 integers values (128 lstm cells)\nencoder = tf.keras.layers.LSTM(units=128, return_state=True)\n\nencoder_output, h, c = encoder(encoder_embedding_out)\nencoder_output = tf.keras.layers.Dense(units = 1024, activation = 'softmax')(encoder_output)\nencoder_states = [h, c]\n\nrnn = tf.keras.Model(inputs = encoder_input, outputs = encoder_output)\n\n\n# ---------------------Merging--------------------------------\n\nx1 = cnn.output \nx2 = rnn.output \n\nmerging_layer = tf.keras.layers.Multiply()([x1,x2])\nclassifier = tf.keras.layers.Dense(units=512,activation='relu')(merging_layer)\nclassifier = tf.keras.layers.Dense(units=512,activation='relu')(classifier)\nclassifier = tf.keras.layers.Dense(units=num_classes, activation='softmax')(classifier)\n\nVQA_model = tf.keras.Model(inputs = [cnn.input,rnn.input], outputs = classifier)\n\nVQA_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Optimization params\n# -------------------\n\n# Loss\nloss = tf.keras.losses.CategoricalCrossentropy()\n\n# learning rate\nlr = 1e-5\noptimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n# -------------------\n\n# Validation metrics\n# ------------------\n\nmetrics = ['accuracy']\n# ------------------\n\n# Compile Model\nVQA_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 10\n\nhistory = VQA_model.fit(\n    train_dataset,\n    validation_data=valid_dataset,\n    epochs=epochs,\n    verbose=1,\n    callbacks=None,\n    steps_per_epoch = int(len(train_gen)/batch_size),\n    validation_steps = int(len(valid_gen)/batch_size)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot graphs\n# not always we have tensorboard enabled\n\nidx = 1\nmtr = ['loss','accuracy']\n\nplt.figure(figsize=(25, 8))\n\nfor m in mtr:\n    x = history.history[m]\n    val_x = history.history['val_' + m]\n\n    plt.subplot(1, len(mtr), idx)\n    plt.plot(x, label='Training ' + m)\n    plt.plot(val_x, label='Validation ' + m)\n    plt.legend(loc='lower right')\n    plt.title('Training and Validation ' + m)\n    idx += 1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef predict(item, model):\n\n    img = load_image(item[\"image_path\"])\n\n    dt = {'image': img, 'question': item[\"question\"]}\n\n    res = model.predict(dt)\n    return np.argmax(p) # return index of best class that is our porediction\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom datetime import datetime\n\ndef create_csv(results, results_dir='./'):\n\n    csv_fname = 'results_'\n    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n\n    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n\n        f.write('Id,Category\\n')\n\n        for key, value in results.items():\n            f.write(key + ',' + str(value) + '\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load train json\ntest_data = []\n\nwith open(test_json_path) as json_file:\n    test_data = json.load(json_file)\n\n# normalize questions and answers\nfor k in test_data:\n    test_data[k][\"question\"] = normalize_question(train_data[k][\"question\"])\n    test_data[k][\"image_path\"] = make_image_path(train_data[k][\"image_id\"])\n\n\n# make predictions\noutput = {}\nfor k in test_data:\n    res = predict(test_data[k], VQA_model)\n    output[k] = res\n\ncreate_csv(output, results_dir=output_dir)\n\nprint(\"Ok :3\")\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}