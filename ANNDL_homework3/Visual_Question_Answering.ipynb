{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Visual_Question_Answering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9QX16bHpU77"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np \r\n",
        "import os\r\n",
        "\r\n",
        "\r\n",
        "SEED = 1234\r\n",
        "\r\n",
        "tf.random.set_seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "\r\n",
        "working_directory = os.getcwd()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN-1kerc3otJ",
        "outputId": "bbbbcf78-45cd-47cc-e771-b8f34554ead2"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(os.path.join(working_directory,'gdrive'))\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMvgPwTL30lI",
        "outputId": "9a63d046-8c8a-43dd-e0a9-0a1b3701b2c8"
      },
      "source": [
        "!unzip gdrive/MyDrive/anndl-2020-vqa.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  gdrive/MyDrive/anndl-2020-vqa.zip\n",
            "replace VQA_Dataset/Images/0.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxOvjI-f5nLQ",
        "outputId": "37e056cb-8657-44f6-c8c2-4b79c4b81b1a"
      },
      "source": [
        "!ls VQA_Dataset"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images\tRImages  test_questions.json  train_questions_annotations.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylHhlMwwqjCM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fae6043-96ba-43a0-86e8-10b397d3ce9f"
      },
      "source": [
        "from PIL import Image\r\n",
        "\r\n",
        "dataset_dir = os.path.join(working_directory,'VQA_Dataset')\r\n",
        "\r\n",
        "img_directory = os.path.join(working_directory,'VQA_Dataset/Images')\r\n",
        "r_img_directory = os.path.join(working_directory,'VQA_Dataset/RImages')\r\n",
        "\r\n",
        "img_names = os.listdir(img_directory)\r\n",
        "print(img_names[:10])\r\n",
        "\r\n",
        "if not os.path.exists(r_img_directory):\r\n",
        "  os.mkdir(r_img_directory)\r\n",
        "\r\n",
        "for i in img_names:\r\n",
        "  img_path = os.path.join(img_directory,i)\r\n",
        "  img = Image.open(img_path).convert('RGB')\r\n",
        "  img = img.resize([224,224])\r\n",
        "  img = img.save(os.path.join(r_img_directory,i))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['14872.png', '902.png', '7704.png', '5192.png', '8913.png', '9777.png', '386.png', '7985.png', '5280.png', '25344.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a3fr6VrslRU"
      },
      "source": [
        "# importing json as python dictionaries \r\n",
        "\r\n",
        "import json \r\n",
        "\r\n",
        "with open(os.path.join(dataset_dir,'train_questions_annotations.json')) as json_file:\r\n",
        "  train_questions_annotations = json.load(json_file)\r\n",
        "\r\n",
        "with open(os.path.join(dataset_dir,'test_questions.json')) as json_file:\r\n",
        "  test_questions = json.load(json_file)\r\n",
        "\r\n",
        "\r\n",
        "image_labels_ = os.listdir(os.path.join(dataset_dir,'Images'))\r\n",
        "image_labels = []\r\n",
        "\r\n",
        "for name in image_labels_:\r\n",
        "  image_labels.append(name[:-4])\r\n",
        "\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfxMIWvXujBK",
        "outputId": "f047082c-c56a-40fd-e133-7962196d972e"
      },
      "source": [
        "questions = {}\r\n",
        "answers   = {}\r\n",
        "\r\n",
        "count = 0\r\n",
        "\r\n",
        "for key in train_questions_annotations:\r\n",
        "  questions[key] = {}\r\n",
        "  questions[key][\"question\"] = train_questions_annotations[key][\"question\"]\r\n",
        "  questions[key][\"image_id\"] = train_questions_annotations[key][\"image_id\"]\r\n",
        "  answers[key] = {}\r\n",
        "  answers[key][\"answer\"] = train_questions_annotations[key][\"answer\"]\r\n",
        "  answers[key][\"image_id\"] = train_questions_annotations[key][\"image_id\"]\r\n",
        "  if (count < 3 ):\r\n",
        "    print(f\"question {key}: {questions[key]}\")\r\n",
        "    print(f\"answer {key}: {answers[key]}\")\r\n",
        "  count += 1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "question 117792: {'question': 'Who looks happier?', 'image_id': '11779'}\n",
            "answer 117792: {'answer': 'man', 'image_id': '11779'}\n",
            "question 117790: {'question': 'Where is the woman sitting?', 'image_id': '11779'}\n",
            "answer 117790: {'answer': 'blanket', 'image_id': '11779'}\n",
            "question 117791: {'question': 'Where is the man sitting?', 'image_id': '11779'}\n",
            "answer 117791: {'answer': 'bench', 'image_id': '11779'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xwSDeUPzYPK"
      },
      "source": [
        "labels_dict = {\r\n",
        "        '0': 0,\r\n",
        "        '1': 1,\r\n",
        "        '2': 2,\r\n",
        "        '3': 3,\r\n",
        "        '4': 4,\r\n",
        "        '5': 5,\r\n",
        "        'apple': 6,\r\n",
        "        'baseball': 7,\r\n",
        "        'bench': 8,\r\n",
        "        'bike': 9,\r\n",
        "        'bird': 10,\r\n",
        "        'black': 11,\r\n",
        "        'blanket': 12,\r\n",
        "        'blue': 13,\r\n",
        "        'bone': 14,\r\n",
        "        'book': 15,\r\n",
        "        'boy': 16,\r\n",
        "        'brown': 17,\r\n",
        "        'cat': 18,\r\n",
        "        'chair': 19,\r\n",
        "        'couch': 20,\r\n",
        "        'dog': 21,\r\n",
        "        'floor': 22,\r\n",
        "        'food': 23,\r\n",
        "        'football': 24,\r\n",
        "        'girl': 25,\r\n",
        "        'grass': 26,\r\n",
        "        'gray': 27,\r\n",
        "        'green': 28,\r\n",
        "        'left': 29,\r\n",
        "        'log': 30,\r\n",
        "        'man': 31,\r\n",
        "        'monkey bars': 32,\r\n",
        "        'no': 33,\r\n",
        "        'nothing': 34,\r\n",
        "        'orange': 35,\r\n",
        "        'pie': 36,\r\n",
        "        'plant': 37,\r\n",
        "        'playing': 38,\r\n",
        "        'red': 39,\r\n",
        "        'right': 40,\r\n",
        "        'rug': 41,\r\n",
        "        'sandbox': 42,\r\n",
        "        'sitting': 43,\r\n",
        "        'sleeping': 44,\r\n",
        "        'soccer': 45,\r\n",
        "        'squirrel': 46,\r\n",
        "        'standing': 47,\r\n",
        "        'stool': 48,\r\n",
        "        'sunny': 49,\r\n",
        "        'table': 50,\r\n",
        "        'tree': 51,\r\n",
        "        'watermelon': 52,\r\n",
        "        'white': 53,\r\n",
        "        'wine': 54,\r\n",
        "        'woman': 55,\r\n",
        "        'yellow': 56,\r\n",
        "        'yes': 57\r\n",
        "}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL2tAmJP9mJz",
        "outputId": "f626e017-9afa-41d0-8424-46059b619e06"
      },
      "source": [
        "def process_answer(answer_string):\r\n",
        "  return labels_dict[answer_string]\r\n",
        "\r\n",
        "count = 0\r\n",
        "\r\n",
        "for key in answers:\r\n",
        "  answers[key]['answer'] = process_answer(answers[key]['answer'])\r\n",
        "  if (count < 5):\r\n",
        "    print(f\"answer {key}: {answers[key]['answer']}\")\r\n",
        "  count += 1\r\n",
        "\r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "answer 117792: 31\n",
            "answer 117790: 12\n",
            "answer 117791: 8\n",
            "answer 55360: 57\n",
            "answer 169490: 31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZMHxBWJJN79",
        "outputId": "21969416-6d19-4fa1-8cde-f5953ae12422"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "# preparing tokenizer for the questions\r\n",
        "MAX_NUM_WORDS = 1e4\r\n",
        "\r\n",
        "questions_set = set()\r\n",
        "\r\n",
        "for key in questions:\r\n",
        "  questions_set.add(questions[key]['question'] + '<eos>')\r\n",
        "for key in test_questions:\r\n",
        "  questions_set.add(test_questions[key]['question'] + '<eos>')\r\n",
        "\r\n",
        "q_tokenizer = Tokenizer(num_words = MAX_NUM_WORDS, filters = '?-,.')\r\n",
        "q_tokenizer.fit_on_texts(questions_set)\r\n",
        "q_wtoi = q_tokenizer.word_index\r\n",
        "\r\n",
        "print(q_wtoi['who'])\r\n",
        "\r\n",
        "max = 0\r\n",
        "for key in q_wtoi:\r\n",
        "  if(q_wtoi[key] > max):\r\n",
        "    max = q_wtoi[key]\r\n",
        "\r\n",
        "print(max)\r\n",
        "q_words = max"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n",
            "4670\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SHSt9q6L0OT"
      },
      "source": [
        "def process_question(q_string):\r\n",
        "  q_string = str(q_string).replace('-',' ')\r\n",
        "  q_string = str(q_string).replace(',',' ')\r\n",
        "  q_string = str(q_string).replace('.',' ')\r\n",
        "  q_string = str(q_string).replace('?',' ')\r\n",
        "  q_splitted = q_string.split()\r\n",
        "  result = []\r\n",
        "  for wq in q_splitted:\r\n",
        "    if(len(wq) > 0):\r\n",
        "      try:\r\n",
        "        result.append(q_wtoi[wq.lower()])\r\n",
        "      except: #occurs when there is another ?\r\n",
        "        print(f\"exception raised on {q_string}\")\r\n",
        "\r\n",
        "  result.append(q_wtoi['<eos>'])\r\n",
        "  return result\r\n",
        "\r\n",
        "for key in questions:\r\n",
        "  questions[key]['question'] = process_question(questions[key]['question'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVm19wiTNpzQ"
      },
      "source": [
        "from PIL import Image\r\n",
        "\r\n",
        "images_dir = os.path.join(dataset_dir,'Images')\r\n",
        "# image_labels contains the id of the images and all png's\r\n",
        "image_paths = {}\r\n",
        "\r\n",
        "for id in image_labels:\r\n",
        "  image_paths[id] = os.path.join(images_dir,id+'.png')\r\n",
        "\r\n",
        "# image paths is a dictionary which associates id of the image to its path, used by the custom generator\r\n",
        "\r\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcsNnsm8yK0u"
      },
      "source": [
        "# pad questions in questions dict\r\n",
        "max_question_length = 0\r\n",
        "\r\n",
        "for key in questions:\r\n",
        "  if (len(questions[key]['question'])>max_question_length):\r\n",
        "    max_question_length = len(questions[key]['question'])\r\n",
        "    \r\n",
        "for key in questions:\r\n",
        "  pad_num = max_question_length - len(questions[key]['question'])\r\n",
        "  for i in range(0,pad_num):\r\n",
        "    questions[key]['question'].append(0)\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlQk-_MAOWlP"
      },
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\r\n",
        "    def __init__(self, max_question_length,questions_dict, answers_dict, batch_size, num_classes=None, shuffle=True):\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.id_list = [key for key in questions_dict]\r\n",
        "        self.shuffle = shuffle\r\n",
        "        self.questions_dict = questions_dict\r\n",
        "        self.answers_dict = answers_dict\r\n",
        "        self.on_epoch_end()\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.id_list) // self.batch_size\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\r\n",
        "        batch = [self.id_list[k] for k in index] # list of id_s for the batch \r\n",
        "\r\n",
        "        i = np.array(np.zeros(shape = [self.batch_size,224,224,3], dtype = np.float32))\r\n",
        "        q = np.array(np.zeros(shape = [self.batch_size,max_question_length], dtype = np.float32))\r\n",
        "        y = np.array(np.zeros(shape = [self.batch_size,58], dtype = np.float32))\r\n",
        "\r\n",
        "        count = 0\r\n",
        "        for id in batch:\r\n",
        "          \r\n",
        "          img_path = os.path.join(r_img_directory,self.questions_dict[id]['image_id']+'.png')\r\n",
        "          img = Image.open(img_path)\r\n",
        "          img_array = np.array(img)\r\n",
        "          i[count,:,:,:] = img_array\r\n",
        "          q[count,:] = self.questions_dict[id]['question']\r\n",
        "          y[count,:] = tf.keras.utils.to_categorical(self.answers_dict[id]['answer'], num_classes=58, dtype='float32')\r\n",
        "          count += 1\r\n",
        "        \r\n",
        "        X = [i,q]\r\n",
        "        return X, y\r\n",
        "\r\n",
        "    def on_epoch_end(self):\r\n",
        "        self.index = np.arange(len(self.id_list)) #np.arange(2) = [0,1,2]\r\n",
        "        if self.shuffle == True:\r\n",
        "            np.random.shuffle(self.index)\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmAu3Hvf-wTq"
      },
      "source": [
        "target_shape = [224,224]\r\n",
        "\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# splitting validation and training set\r\n",
        "keys = [key for key in questions]\r\n",
        "np.random.shuffle(keys)\r\n",
        "\r\n",
        "split_percentage = 0.92\r\n",
        "\r\n",
        "training_keys = keys[0:int(split_percentage*len(keys))]\r\n",
        "validation_keys = keys[int(split_percentage*len(keys)):]\r\n",
        "\r\n",
        "training_questions = {}\r\n",
        "training_answers = {}\r\n",
        "\r\n",
        "validation_questions = {}\r\n",
        "validation_answers = {}\r\n",
        "\r\n",
        "for key in training_keys:\r\n",
        "  training_questions[key] = {}\r\n",
        "  training_questions[key]['question'] = questions[key]['question']\r\n",
        "  training_questions[key]['image_id'] = questions[key]['image_id']\r\n",
        "  training_answers[key] = {}\r\n",
        "  training_answers[key]['answer'] = answers[key]['answer']\r\n",
        "  training_answers[key]['image_id'] = answers[key]['image_id']\r\n",
        "\r\n",
        "for key in validation_keys:\r\n",
        "  validation_questions[key] = {}\r\n",
        "  validation_questions[key]['question'] = questions[key]['question']\r\n",
        "  validation_questions[key]['image_id'] = questions[key]['image_id']\r\n",
        "  validation_answers[key] = {}\r\n",
        "  validation_answers[key]['answer'] = answers[key]['answer']\r\n",
        "  validation_answers[key]['image_id'] = answers[key]['image_id']\r\n",
        "\r\n",
        "\r\n",
        "train_generator = DataGenerator(max_question_length = max_question_length,\r\n",
        "                                questions_dict      = training_questions,\r\n",
        "                                answers_dict        = training_answers,\r\n",
        "                                batch_size          = batch_size,\r\n",
        "                                num_classes         = None,\r\n",
        "                                shuffle             = True)\r\n",
        "\r\n",
        "validation_generator = DataGenerator(max_question_length = max_question_length,\r\n",
        "                                questions_dict      = validation_questions,\r\n",
        "                                answers_dict        = validation_answers,\r\n",
        "                                batch_size          = batch_size,\r\n",
        "                                num_classes         = None,\r\n",
        "                                shuffle             = True)\r\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIBIbHkHPwZm"
      },
      "source": [
        "# **Prepare the model**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GFyByXMPv_C"
      },
      "source": [
        "\r\n",
        "def create_model(percentage,out_units,n,dr,lr,embedding):\r\n",
        "  num_classes = 58\r\n",
        "\r\n",
        "  # ------------------------ CNN ----------------------\r\n",
        "\r\n",
        "  vgg = tf.keras.applications.Xception(include_top = False, input_shape = [224,224,3])\r\n",
        "#0.7 63 XCeption\r\n",
        "  for l in vgg.layers[:int(len(vgg.layers)*percentage)]:\r\n",
        "    l.trainable = False \r\n",
        "\r\n",
        "  vgg_output = tf.keras.layers.GlobalAveragePooling2D()(vgg.output)\r\n",
        "  vgg_output = tf.keras.layers.Dense(units = out_units,activation = 'relu')(vgg_output)\r\n",
        "\r\n",
        "  cnn = tf.keras.Model(inputs = vgg.input, outputs = vgg_output)\r\n",
        "\r\n",
        "\r\n",
        "  # ------------------------ RNN ----------------------\r\n",
        "\r\n",
        "  EMBEDDING_SIZE = embedding\r\n",
        "\r\n",
        "  # ENCODER\r\n",
        "  # -------\r\n",
        "  # in keras out = layer(input)\r\n",
        "\r\n",
        "  encoder_input = tf.keras.Input(shape=[max_question_length])\r\n",
        "  encoder_embedding_layer = tf.keras.layers.Embedding(len(q_wtoi)+1, EMBEDDING_SIZE, input_length=max_question_length, mask_zero=True)\r\n",
        "  encoder_embedding_out = encoder_embedding_layer(encoder_input)\r\n",
        "\r\n",
        "  # I need 224 units because I have 4 words each embedded in 32 integers values \r\n",
        "  encoder = tf.keras.layers.LSTM(units=128, return_state=True)\r\n",
        "\r\n",
        "  encoder_output, h, c = encoder(encoder_embedding_out)\r\n",
        "  encoder_output = tf.keras.layers.Dense(units = out_units, activation = 'relu')(encoder_output)\r\n",
        "\r\n",
        "  encoder_states = [h, c]\r\n",
        "\r\n",
        "  rnn = tf.keras.Model(inputs = encoder_input, outputs = encoder_output)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  # ---------------------Merging--------------------------------\r\n",
        "\r\n",
        "  x1 = cnn.output \r\n",
        "  x2 = rnn.output \r\n",
        "\r\n",
        "  merging_layer = tf.keras.layers.Multiply()([x1,x2])\r\n",
        "  flatten = tf.keras.layers.Flatten()(merging_layer)\r\n",
        "  flatten = tf.keras.layers.BatchNormalization()(flatten)\r\n",
        "  classifier = tf.keras.layers.Dense(units=n,activation='relu')(flatten)\r\n",
        "  classifier = tf.keras.layers.Dropout(rate = dr)(classifier)\r\n",
        "  classifier = tf.keras.layers.Dense(units=n,activation='relu')(classifier)\r\n",
        "  classifier = tf.keras.layers.Dropout(rate = dr)(classifier)\r\n",
        "  classifier = tf.keras.layers.Dense(units=num_classes,activation='softmax')(classifier)\r\n",
        "  VQA_model = tf.keras.Model(inputs = [cnn.input,rnn.input], outputs = classifier)\r\n",
        "\r\n",
        "\r\n",
        "  # Loss\r\n",
        "  loss = tf.keras.losses.CategoricalCrossentropy()\r\n",
        "\r\n",
        "  # learning rate\r\n",
        "  lr = lr\r\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\r\n",
        "  # -------------------\r\n",
        "\r\n",
        "  # Validation metrics\r\n",
        "  # ------------------\r\n",
        "\r\n",
        "  metrics = ['accuracy']\r\n",
        "  # ------------------\r\n",
        "\r\n",
        "  # Compile Model\r\n",
        "  VQA_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\r\n",
        "\r\n",
        "  return VQA_model\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uapE_kWUwVBw"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtLA1SEWD-kM"
      },
      "source": [
        "\r\n",
        "\r\n",
        "batch_size = 64\r\n",
        "\r\n",
        "\r\n",
        "callbacks = []\r\n",
        "\r\n",
        "checkpoint_dir = os.path.join(working_directory,'callbacks')\r\n",
        "\r\n",
        "if not os.path.exists(checkpoint_dir):\r\n",
        "  os.mkdir(checkpoint_dir)\r\n",
        "\r\n",
        "callbacks.append(tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath = checkpoint_dir, monitor='val_loss', verbose=0, save_best_only=True,\r\n",
        "    save_weights_only=True, mode='auto', save_freq='epoch'))\r\n",
        "\r\n",
        "\r\n",
        "callbacks.append(tf.keras.callbacks.EarlyStopping(\r\n",
        "    monitor='val_accuracy', patience=5, verbose=0,\r\n",
        "    mode='auto', baseline=None, restore_best_weights=True\r\n",
        "))\r\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPiXUGGBEnOj"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG1cx1W7En5t"
      },
      "source": [
        "## Models to train ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG9wdmscDn2G"
      },
      "source": [
        "model_1 = {\r\n",
        "    \"learning_rate\" : 0.5e-3,\r\n",
        "    \"percentage\": 0.7,\r\n",
        "    \"dropout_rate\": 0.1,\r\n",
        "    \"out_units\": 512,\r\n",
        "    \"n_units\": 256,\r\n",
        "    \"embedding\": 32\r\n",
        "}\r\n",
        "model_2 = {\r\n",
        "    \"learning_rate\" : 0.5e-3,\r\n",
        "    \"percentage\": 0.7,\r\n",
        "    \"dropout_rate\": 0.2,\r\n",
        "    \"out_units\": 512,\r\n",
        "    \"n_units\": 512,\r\n",
        "     \"embedding\": 64\r\n",
        "}\r\n",
        "model_3 = {\r\n",
        "    \"learning_rate\" : 0.5e-3,\r\n",
        "    \"percentage\": 0.,\r\n",
        "    \"dropout_rate\": 0.3,\r\n",
        "    \"out_units\": 512,\r\n",
        "    \"n_units\": 512,\r\n",
        "     \"embedding\": 64\r\n",
        "}\r\n",
        "model_4 = {\r\n",
        "    \"learning_rate\" : 0.5e-3,\r\n",
        "    \"percentage\": 0.7,\r\n",
        "    \"dropout_rate\": 0.3,\r\n",
        "    \"out_units\": 1024,\r\n",
        "    \"n_units\": 512,\r\n",
        "     \"embedding\": 128\r\n",
        "}\r\n",
        "model_5 = {\r\n",
        "    \"learning_rate\" : 1e-4,\r\n",
        "    \"percentage\": 0.7,\r\n",
        "    \"dropout_rate\": 0.15,\r\n",
        "    \"out_units\": 512,\r\n",
        "    \"n_units\": 256,\r\n",
        "     \"embedding\": 32\r\n",
        "}\r\n",
        "model_6 = {\r\n",
        "    \"learning_rate\" : 1e-4,\r\n",
        "    \"percentage\": 0.7,\r\n",
        "    \"dropout_rate\": 0.2,\r\n",
        "    \"out_units\": 512,\r\n",
        "    \"n_units\": 256,\r\n",
        "     \"embedding\": 32\r\n",
        "}\r\n",
        "model_7 = {\r\n",
        "    \"learning_rate\" : 1e-4,\r\n",
        "    \"percentage\": 0.,\r\n",
        "    \"dropout_rate\": 0.25,\r\n",
        "    \"out_units\": 512,\r\n",
        "    \"n_units\": 512,\r\n",
        "     \"embedding\": 32\r\n",
        "}\r\n",
        "model_8 = {\r\n",
        "    \"learning_rate\" : 1e-4,\r\n",
        "    \"percentage\": 0.,\r\n",
        "    \"dropout_rate\": 0.3,\r\n",
        "    \"out_units\": 1024,\r\n",
        "    \"n_units\": 512,\r\n",
        "    \"embedding\": 64\r\n",
        "}\r\n",
        "\r\n",
        "model_9 = {\r\n",
        "    \"learning_rate\" : 1e-5,\r\n",
        "    \"percentage\": 0.,\r\n",
        "    \"dropout_rate\": 0.25,\r\n",
        "    \"out_units\": 1024,\r\n",
        "    \"n_units\": 512,\r\n",
        "     \"embedding\": 32\r\n",
        "}\r\n",
        "model_10 = {\r\n",
        "    \"learning_rate\" : 1e-5,\r\n",
        "    \"percentage\": 0.,\r\n",
        "    \"dropout_rate\": 0.3,\r\n",
        "    \"out_units\": 1024,\r\n",
        "    \"n_units\": 1024,\r\n",
        "     \"embedding\": 64\r\n",
        "}\r\n",
        "model_10 = {\r\n",
        "    \"learning_rate\" : 1e-5,\r\n",
        "    \"percentage\": 0.,\r\n",
        "    \"dropout_rate\": 0.3,\r\n",
        "    \"out_units\": 1024,\r\n",
        "    \"n_units\": 1024,\r\n",
        "     \"embedding\": 128\r\n",
        "}\r\n",
        "\r\n",
        "models = []\r\n",
        "models.append(model_1)\r\n",
        "models.append(model_2)\r\n",
        "models.append(model_3)\r\n",
        "models.append(model_4)\r\n",
        "models.append(model_5)\r\n",
        "models.append(model_6)\r\n",
        "models.append(model_7)\r\n",
        "models.append(model_8)\r\n",
        "models.append(model_9)\r\n",
        "models.append(model_10)\r\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCyuG5jIr7gz"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "histories = {}\r\n",
        "count = 1\r\n",
        "\r\n",
        "for m in models:\r\n",
        "  model = create_model(percentage = m[\"percentage\"],out_units = m[\"out_units\"],n = m[\"n_units\"],dr = m[\"dropout_rate\"],lr = m[\"learning_rate\"],embedding = m[\"embedding\"])\r\n",
        "\r\n",
        "  history = model.fit(train_generator, validation_data = validation_generator,\r\n",
        "  epochs=20, verbose=0, callbacks=None,\r\n",
        "  steps_per_epoch = int(len(training_questions)/batch_size))\r\n",
        "  histories[\"model_\"+str(count)] = history.history\r\n",
        "  print(f\"Model with learning rate: {m['learning_rate']},output units: {m['out_units']}, percentage freezed: {m['percentage']}, units in classifier: {m['n_units']}, drop rate: {m['dropout_rate']},embedding :{m['embedding']}\")\r\n",
        "  print(f\"Maximum validation accuracy: {np.max(history.history['val_accuracy'])}, Min validation loss: {np.min(history.history['val_loss'])}\")\r\n",
        "  count += 1\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck40Udbt8Q1K"
      },
      "source": [
        "## **Model selection after Cross validation** ##\r\n",
        "## 10 models trained w/ different comb. of reasonable hyperparameters ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEGcF8gG4z2M"
      },
      "source": [
        "batch_size = 32\r\n",
        "\r\n",
        "\r\n",
        "callbacks = []\r\n",
        "\r\n",
        "checkpoint_dir = os.path.join(working_directory,'callbacks')\r\n",
        "\r\n",
        "if not os.path.exists(checkpoint_dir):\r\n",
        "  os.mkdir(checkpoint_dir)\r\n",
        "\r\n",
        "callbacks.append(tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath = checkpoint_dir, monitor='val_loss', verbose=0, save_best_only=True,\r\n",
        "    save_weights_only=True, mode='auto', save_freq='epoch'))\r\n",
        "\r\n",
        "\r\n",
        "callbacks.append(tf.keras.callbacks.EarlyStopping(\r\n",
        "    monitor='val_accuracy', patience=5, verbose=0,\r\n",
        "    mode='auto', baseline=None, restore_best_weights=True\r\n",
        "))\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwrPu0DZ42PL"
      },
      "source": [
        "## Select the best model and train with early stopping with high patience ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrdqense5y9m"
      },
      "source": [
        "target_shape = [224,224]\r\n",
        "\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# splitting validation and training set\r\n",
        "keys = [key for key in questions]\r\n",
        "np.random.shuffle(keys)\r\n",
        "\r\n",
        "split_percentage = 1\r\n",
        "\r\n",
        "training_keys = keys[0:int(split_percentage*len(keys))]\r\n",
        "validation_keys = keys[int(split_percentage*len(keys)):]\r\n",
        "\r\n",
        "training_questions = {}\r\n",
        "training_answers = {}\r\n",
        "\r\n",
        "validation_questions = {}\r\n",
        "validation_answers = {}\r\n",
        "\r\n",
        "for key in training_keys:\r\n",
        "  training_questions[key] = {}\r\n",
        "  training_questions[key]['question'] = questions[key]['question']\r\n",
        "  training_questions[key]['image_id'] = questions[key]['image_id']\r\n",
        "  training_answers[key] = {}\r\n",
        "  training_answers[key]['answer'] = answers[key]['answer']\r\n",
        "  training_answers[key]['image_id'] = answers[key]['image_id']\r\n",
        "\r\n",
        "for key in validation_keys:\r\n",
        "  validation_questions[key] = {}\r\n",
        "  validation_questions[key]['question'] = questions[key]['question']\r\n",
        "  validation_questions[key]['image_id'] = questions[key]['image_id']\r\n",
        "  validation_answers[key] = {}\r\n",
        "  validation_answers[key]['answer'] = answers[key]['answer']\r\n",
        "  validation_answers[key]['image_id'] = answers[key]['image_id']\r\n",
        "\r\n",
        "\r\n",
        "train_generator = DataGenerator(max_question_length = max_question_length,\r\n",
        "                                questions_dict      = training_questions,\r\n",
        "                                answers_dict        = training_answers,\r\n",
        "                                batch_size          = batch_size,\r\n",
        "                                num_classes         = None,\r\n",
        "                                shuffle             = True)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F1gxfOLA6GU"
      },
      "source": [
        "# lowest loss model:\r\n",
        "\r\n",
        "min = 99\r\n",
        "count = 1\r\n",
        "for k in histories:\r\n",
        "  if (k[\"val_loss\"]<min):\r\n",
        "    min = k[\"val_loss\"]\r\n",
        "    best = count\r\n",
        "  count += 1\r\n",
        "\r\n",
        "model = models[best]\r\n",
        "VQA_model = create_model(percentage = model[\"percentage\"],out_units= model[\"out_units\"],n= model[\"n_units\"],dr= model[\"dropout_rate\"],lr= model[\"learning_rate\"],embedding= model[\"embedding\"])\r\n",
        "history = VQA_model.fit(train_generator, validation_data = validation_generator,\r\n",
        "  epochs=35, verbose=1, callbacks=None,\r\n",
        "  steps_per_epoch = int(len(training_questions)/batch_size))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoWMHOjxu7bb"
      },
      "source": [
        "# **Preparing the test evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFsSdk-b0c96"
      },
      "source": [
        "\r\n",
        "\r\n",
        "for key in test_questions:\r\n",
        "  test_questions[key]['question'] = process_question(test_questions[key]['question'])\r\n",
        "\r\n",
        "for key in test_questions:\r\n",
        "  pad_num = max_question_length - len(test_questions[key]['question'])\r\n",
        "  for i in range(0,pad_num):\r\n",
        "    test_questions[key]['question'].append(0)\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLDOHa-GyTgb"
      },
      "source": [
        "print(test_questions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K6huSMowdy2"
      },
      "source": [
        "          \r\n",
        "# img_path = os.path.join(images_dir,self.questions_dict[id]['image_id']+'.png')\r\n",
        "# img = Image.open(os.path.join(images_dir,img_path)).convert('RGB')\r\n",
        "# img = img.resize([224,224])\r\n",
        "# img_array = np.array(img)\r\n",
        "\r\n",
        "test_len = len(test_questions)\r\n",
        "\r\n",
        "\r\n",
        "test_dataset = []\r\n",
        "\r\n",
        "i = np.array(np.zeros(shape = [test_len,224,224,3], dtype = np.float32))\r\n",
        "q = np.array(np.zeros(shape = [test_len,max_question_length], dtype = np.float32))\r\n",
        "\r\n",
        "count = 0 \r\n",
        "for key in test_questions:\r\n",
        "  img_path = os.path.join(images_dir,test_questions[key]['image_id']+'.png')\r\n",
        "  img = Image.open(os.path.join(images_dir,img_path)).convert('RGB')\r\n",
        "  img = img.resize([224,224])\r\n",
        "  img_array = np.array(img)\r\n",
        "  i[count,:,:,:] = img_array\r\n",
        "  q[count,:] = test_questions[key]['question']\r\n",
        "  count += 1\r\n",
        "\r\n",
        "test_dataset = [i,q]\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvlttE_C0qty"
      },
      "source": [
        "print(test_dataset[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Sr-hEbJyDMG"
      },
      "source": [
        "\r\n",
        "predictions = VQA_model.predict(x = test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crait-Sw0kve"
      },
      "source": [
        "eval_dict = {}\r\n",
        "pred = [] \r\n",
        "for p in predictions:\r\n",
        "  pred.append(int(tf.math.argmax(p)))\r\n",
        "\r\n",
        "count = 0\r\n",
        "for key in test_questions:\r\n",
        "  eval_dict[key] = pred[count]\r\n",
        "  count += 1\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTi3M7H006Wm"
      },
      "source": [
        "print(eval_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9jITaxa3CN2"
      },
      "source": [
        "eval_dir = os.path.join(working_directory,'gdrive/MyDrive')\r\n",
        "\r\n",
        "def create_csv(eval_dict, results_dir):\r\n",
        "\r\n",
        "    csv_fname = 'EVAL_h3_21'\r\n",
        "\r\n",
        "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\r\n",
        "\r\n",
        "        f.write('Id,Category\\n')\r\n",
        "\r\n",
        "        for key, value in eval_dict.items():\r\n",
        "            f.write(key + ',' + str(value) + '\\n')\r\n",
        "\r\n",
        "create_csv(eval_dict=eval_dict, results_dir=eval_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7QJ3qwg3alv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}